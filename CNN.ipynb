{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is demo of simple Convolutional Neural Network\n",
    "\n",
    "Convolutional Neural Network is an example of an deep neural network.\n",
    "It learns itself without any hard coding about the variables.\n",
    "Applications: Image and video classification, recommender systems, NLPs etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here I'm using tensor flow as backend\n",
    "You can use Theano, CNTK(offers great performance) as well.\n",
    "To change to theano, edit 'backend' to 'theano' in 'C:/Users/(User)/.keras/keras.json'  (Win 10 user here)\n",
    "Well you need to restart the kernel after swithching from theano to tensorflow and viceversa\n",
    "\"\"\"\n",
    "\n",
    "#Importing the libraries\n",
    "\n",
    "from keras.models import Sequential\n",
    "#This defines the type of model I am using which is sequential\n",
    "\n",
    "from keras.layers import Convolution2D\n",
    "#This defines that I am using convolutin 2D layer\n",
    "\n",
    "from keras.layers import MaxPooling2D\n",
    "\"\"\"\n",
    "Ex: this converts 4x4 matrix to 2x2 matrix using 2x2 pooling filter. \n",
    "In neural networks images are expressed as matrix.\n",
    "Thats the reason we use matrix operations. \n",
    "GPUs are good at doing matrix operations, that's the reason GPUs are used extensively in deep learning.\n",
    "\"\"\"\n",
    "from keras.layers import Flatten\n",
    "#This flattens the array from (64, 32, 32) to (65536) i.e., 64x32x32 for efficient operations\n",
    "\n",
    "from keras.layers import Dense\n",
    "#This is to add layers in the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chaitra\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#Initializing the CNN, object of the class Sequential()\n",
    "cnn = Sequential()\n",
    "\n",
    "#Initializing convolution layer\n",
    "#input_shape = (256,256,3) tensorflow backend\n",
    "#input_shape = (3,256,256) theano backend\n",
    "#input = 256x256 RGB images (we dont know the size of image, I force the images to be in 256x256)\n",
    "#64 is no of feature detectors(so we get 64 feature maps) (32 is for cpu).3x3 is the shape of convolution filter\n",
    "#relu is rectified linear function, as images are non linear.\n",
    "cnn.add(Convolution2D(64,3,3, input_shape=(64,64,3), activation='relu') )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pooling\n",
    "#max pooling takes the max value in max pool filter.\n",
    "#after max pooling it reduces the input size.\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#flattening\n",
    "#gives single vector from max pooled vector\n",
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chaitra\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=128, activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Chaitra\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, activation=\"sigmoid\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# 2 Hidden layers\n",
    "# 1st hidden layer outputs 128 nodes. its a just a thumb rule.\n",
    "cnn.add(Dense(output_dim=128, activation='relu'))\n",
    "#No need to specify the input dimension, as it is taken care of (one less thing to keep in mind)\n",
    "\n",
    "cnn.add(Dense(output_dim=1,activation='sigmoid'))\n",
    "#sigmoid is used to classify 2 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compiling the cnn\n",
    "\n",
    "\"\"\"\n",
    "other optimizers:\n",
    "1. rmsprop - for recurrent neural networks\n",
    "2. adam - efficient, for large data, huge no of parameters etc\n",
    "other loss functions:\n",
    "1. binary_crossentropy - for binary classess\n",
    "2. categorical_crossentropy - for multiple classess\n",
    "\"\"\"\n",
    "\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fitting CNN to images\n",
    "#to prevent overfitting use image augementation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#for training dataset\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True) \n",
    "#for test set\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#Thumbrule : copy from keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images belonging to 2 classes.\n",
      "Found 6 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "6/6 [==============================] - 2s - loss: 0.0345 - acc: 1.0000 - val_loss: 1.6104 - val_acc: 0.3333\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 2s - loss: 0.0363 - acc: 1.0000 - val_loss: 1.5542 - val_acc: 0.3333\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 2s - loss: 0.0258 - acc: 1.0000 - val_loss: 1.6579 - val_acc: 0.3333\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 2s - loss: 0.0138 - acc: 1.0000 - val_loss: 1.7904 - val_acc: 0.5000\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 2s - loss: 0.0213 - acc: 1.0000 - val_loss: 2.1441 - val_acc: 0.1667\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 2s - loss: 0.0870 - acc: 0.9440 - val_loss: 3.0473 - val_acc: 0.1667\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 2s - loss: 0.0787 - acc: 0.9440 - val_loss: 1.9612 - val_acc: 0.1667\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 2s - loss: 0.0101 - acc: 1.0000 - val_loss: 1.9865 - val_acc: 0.1667\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 2s - loss: 0.0092 - acc: 1.0000 - val_loss: 1.9926 - val_acc: 0.1667\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 2s - loss: 0.0106 - acc: 1.0000 - val_loss: 2.0191 - val_acc: 0.1667\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 2s - loss: 0.0088 - acc: 1.0000 - val_loss: 2.1374 - val_acc: 0.1667\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 2s - loss: 0.0111 - acc: 1.0000 - val_loss: 1.5801 - val_acc: 0.3333\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 2s - loss: 0.0063 - acc: 1.0000 - val_loss: 2.3209 - val_acc: 0.3333\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 2s - loss: 0.0095 - acc: 1.0000 - val_loss: 1.9374 - val_acc: 0.5000\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 2s - loss: 0.0044 - acc: 1.0000 - val_loss: 1.9889 - val_acc: 0.1667\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 2s - loss: 0.0084 - acc: 1.0000 - val_loss: 2.4385 - val_acc: 0.1667\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 2s - loss: 0.0076 - acc: 1.0000 - val_loss: 2.2083 - val_acc: 0.3333\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 2s - loss: 0.0733 - acc: 0.9440 - val_loss: 2.5321 - val_acc: 0.3333\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 2s - loss: 0.1217 - acc: 0.9440 - val_loss: 2.6747 - val_acc: 0.3333\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 2s - loss: 0.2470 - acc: 0.9440 - val_loss: 2.0930 - val_acc: 0.5000\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 2s - loss: 0.0976 - acc: 1.0000 - val_loss: 1.9250 - val_acc: 0.0000e+00\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 2s - loss: 0.0436 - acc: 1.0000 - val_loss: 1.6497 - val_acc: 0.3333\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 2s - loss: 0.0476 - acc: 1.0000 - val_loss: 1.8046 - val_acc: 0.3333\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 2s - loss: 0.0289 - acc: 1.0000 - val_loss: 1.8077 - val_acc: 0.1667\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 2s - loss: 0.0134 - acc: 1.0000 - val_loss: 1.9323 - val_acc: 0.1667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x216ccdcad68>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\n",
    "        'training_set',\n",
    "        target_size=(64,64),\n",
    "        batch_size=3,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'test_set',\n",
    "        target_size=(64,64),\n",
    "        batch_size=3,\n",
    "        class_mode='binary')\n",
    "\n",
    "#steps per epoch = unique samples in training/batch_size\n",
    "#validation steps = unique samples in test/batch_size\n",
    "#epochs = no of iterations on the data\n",
    "cnn.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=6,\n",
    "        epochs=25,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=2)\n",
    "#I am using less no of images as i am running on my local machine\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

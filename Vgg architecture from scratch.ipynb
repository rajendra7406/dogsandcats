{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 from scratch for my dogscats classifier\n",
    "This is possible from MOOC course www.fast.ai\n",
    "Let's have a look at Vgg16 architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vgg16 import VGG16\n",
    "vgg = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Construct the same architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vgg16 has:\n",
    "1. 2 convolution layers with zero padding layer with maxpooling layer\n",
    "2. 2 convolution layers with zero padding layer with maxpooling layer\n",
    "3. 3 convolution layers with zero padding layer with maxpooling layer\n",
    "4. 3 convolution layers with zero padding layer with maxpooling layer\n",
    "5. 3 convolution layers with zero padding layer with maxpooling layer\n",
    "6. With flattening layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vgg16 has 3 Dense layers. \n",
    "1. 1st 2 dense layer with 4096 neurons. \n",
    "2. 3rd dense layer cotains 1000 neurons (because it has to classify 1000 classes). \n",
    "3. It has also dropout layer with value of 0.5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout layer\n",
    "Dropout is used to reduce overfitting. It deletes weigths of certian neurons ( a.k.a deactivating neurons ). Typically it's value is 50% (so 0.5). Some engineers use 0.25, 0.35, 0.45 respectively for each dense layer they add.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Flatten\n",
    "\n",
    "#This will be a sequential model\n",
    "scratch = Sequential()\n",
    "\n",
    "#1\n",
    "scratch.add(Conv2D( 64,( 3, 3), input_shape = (224,224,3), activation='relu') )\n",
    "scratch.add(ZeroPadding2D(padding=(1,1)))\n",
    "scratch.add(Conv2D(64,( 3, 3), activation='relu') )\n",
    "scratch.add(MaxPooling2D(pool_size=(2,2)) )\n",
    "\n",
    "#2\n",
    "scratch.add(ZeroPadding2D(padding=(1,1)))\n",
    "scratch.add(Conv2D(128,( 3, 3),  activation='relu') )\n",
    "scratch.add(ZeroPadding2D(padding=(1,1)))\n",
    "scratch.add(Conv2D(128,( 3, 3),  activation='relu') )\n",
    "scratch.add(MaxPooling2D(pool_size=(2,2)) )\n",
    "\n",
    "#3\n",
    "scratch.add(ZeroPadding2D(padding=(1,1)))\n",
    "scratch.add(Conv2D(256,( 3, 3),  activation='relu') )\n",
    "scratch.add(ZeroPadding2D(padding=(1,1)))\n",
    "scratch.add(Conv2D(256,( 3, 3),  activation='relu') )\n",
    "scratch.add(ZeroPadding2D(padding=(1,1)))\n",
    "scratch.add(Conv2D(256,( 3, 3),  activation='relu') )\n",
    "scratch.add(MaxPooling2D(pool_size=(2,2) ))\n",
    "\n",
    "#3\n",
    "scratch.add(ZeroPadding2D(padding=(1,1)))\n",
    "scratch.add(Conv2D(512,( 3, 3),  activation='relu') )\n",
    "scratch.add(ZeroPadding2D(padding=(1,1)))\n",
    "scratch.add(Conv2D(512,( 3, 3),  activation='relu') )\n",
    "scratch.add(ZeroPadding2D(padding=(1,1)))\n",
    "scratch.add(Conv2D(512,( 3, 3),  activation='relu') )\n",
    "scratch.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#3\n",
    "scratch.add(ZeroPadding2D(padding=(1,1)))\n",
    "scratch.add(Conv2D(512,( 3, 3),  activation='relu') )\n",
    "scratch.add(ZeroPadding2D(padding=(1,1)))\n",
    "scratch.add(Conv2D(512,( 3, 3),  activation='relu') )\n",
    "scratch.add(ZeroPadding2D(padding=(1,1)))\n",
    "scratch.add(Conv2D(512,( 3, 3),  activation='relu') )\n",
    "scratch.add(MaxPooling2D(pool_size=(2,2) ))\n",
    "\n",
    "#Flatten ing layer\n",
    "scratch.add(Flatten())\n",
    "\n",
    "#Dense 1\n",
    "scratch.add(Dense(300,activation='relu'))\n",
    "scratch.add(Dropout(0.5))    \n",
    "\n",
    "#Dense 2\n",
    "scratch.add(Dense(300,activation='relu'))\n",
    "scratch.add(Dropout(0.5))    \n",
    "\n",
    "#Finetuning\n",
    "scratch.add(Dense(1,activation='sigmoid'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scratch.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images belonging to 2 classes.\n",
      "Found 6 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      "3/3 [==============================] - 20s - loss: 9.2935 - acc: 0.2222 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 6s - loss: 3.5623 - acc: 0.7778 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 9s - loss: 8.0188 - acc: 0.5000 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 6s - loss: 10.6868 - acc: 0.3333 - val_loss: 7.9712 - val_acc: 0.5000\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 5s - loss: 9.1739 - acc: 0.4271 - val_loss: 7.9712 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ef9b3334e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "gen = ImageDataGenerator()\n",
    "\n",
    "train_generator = gen.flow_from_directory(\n",
    "        'training_set',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=3,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = gen.flow_from_directory(\n",
    "        'test_set',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=2,\n",
    "        class_mode='binary')\n",
    "#According to vgg16 model, target_size must be 224,224. I have given target_size as 64,64 to avoid errors. \n",
    "# I will figure it out and update. \n",
    "scratch.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=3,\n",
    "        epochs=5,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "scratch.save('vgg_scratch.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: Supposed to be snippet code\n",
    "```python\n",
    "#Dense 1\n",
    "scratch.add(Dense(4096,activation='relu'))\n",
    "scratch.add(Dropout(0.5))    \n",
    "\n",
    "#Dense 2\n",
    "scratch.add(Dense(4096,activation='relu'))\n",
    "scratch.add(Dropout(0.5))    \n",
    "\n",
    "scratch.add(Dense(1,activation='sigmoid'))    \n",
    "```\n",
    "**been changed to** \n",
    "```python\n",
    "#Dense 1\n",
    "scratch.add(Dense(300,activation='relu'))\n",
    "scratch.add(Dropout(0.5))    \n",
    "\n",
    "#Dense 2\n",
    "scratch.add(Dense(300,activation='relu'))\n",
    "scratch.add(Dropout(0.5))    \n",
    "\n",
    "scratch.add(Dense(1,activation='sigmoid'))    \n",
    "```\n",
    "\n",
    "#### Reason: \n",
    "* I ran this code on my local machine, which has low powered GPU. \n",
    "* This hardware limitations gave me \"Resource Exhaustion Error\"\n",
    "* After googling and doing my research.\n",
    "* I changed my 'massive' dense layers \n",
    "* I initially tested 1024, 700,512,400,350\n",
    "* I realized that it can rum on max '300' \n",
    "\n",
    "* So, I finalized this and updated the code. \n",
    "* Accuracy is un imaginably low, It doesnt matter now, as this is completely for educational purposes. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

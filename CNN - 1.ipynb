{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is demo of simple Convolutional Neural Network\n",
    "\n",
    "Convolutional Neural Network is an example of an deep neural network.\n",
    "It learns itself without any hard coding about the variables.\n",
    "Applications: Image and video classification, recommender systems, NLPs etc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'm using tensor flow as backend\n",
    "You can use Theano, CNTK(offers great performance) as well.\n",
    "To change to theano, edit 'backend' to 'theano' in 'C:/Users/(User)/.keras/keras.json'  (Win 10 user here)\n",
    "Well you need to restart the kernel after swithching from theano to tensorflow and viceversa\n",
    "\n",
    "# Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.0.5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This defines the type of model I am using which is sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution Layer\n",
    "This defines that I am using convolutin 2D layer.\n",
    "\n",
    "input_shape = (256,256,3) tensorflow backend\n",
    "input_shape = (3,256,256) theano backend\n",
    "input = 256x256 RGB images (we dont know the size of image, I force the images to be in 256x256)\n",
    "64 is no of feature detectors(so we get 64 feature maps) (32 is for cpu).3x3 is the shape of convolution filter\n",
    "relu is rectified linear function, as images are non linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chaitra\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", input_shape=(64, 64, 3...)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Convolution2D\n",
    "#Initializing the CNN, object of the class Sequential()\n",
    "cnn = Sequential()\n",
    "#Initializing convolution layer\n",
    "cnn.add(Convolution2D(64,3,3, input_shape=(64,64,3), activation='relu') )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max Pooling\n",
    "Ex: this converts 4x4 matrix to 2x2 matrix using 2x2 pooling filter. \n",
    "In neural networks images are expressed as matrix.\n",
    "Thats the reason we use matrix operations. \n",
    "GPUs are good at doing matrix operations, that's the reason GPUs are used extensively in deep learning.\n",
    "\n",
    "Max pooling takes the max value in max pool filter.\n",
    "After max pooling it reduces the input size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D\n",
    "#pooling\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flattening \n",
    "This flattens the array from (64, 32, 32) to (65536) i.e., 64x32x32 for efficient operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Flatten\n",
    "#flattening\n",
    "#gives single vector from max pooled vector\n",
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connecting the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chaitra\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=128, activation=\"relu\")`\n",
      "  \n",
      "C:\\Users\\Chaitra\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, activation=\"sigmoid\")`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "#This is to add layers in the neural network\n",
    "# 2 Hidden layers\n",
    "# 1st hidden layer outputs 128 nodes. its a just a thumb rule.\n",
    "cnn.add(Dense(output_dim=128, activation='relu'))\n",
    "#No need to specify the input dimension, as it is taken care of (one less thing to keep in mind)\n",
    "\n",
    "cnn.add(Dense(output_dim=1,activation='sigmoid'))\n",
    "#sigmoid is used to classify 2 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the CNN\n",
    "Other optimizers:\n",
    "1. rmsprop - for recurrent neural networks\n",
    "2. adam - efficient, for large data, huge no of parameters etc\n",
    "Other loss functions:\n",
    "1. binary_crossentropy - for binary classess\n",
    "2. categorical_crossentropy - for multiple classess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting CNN to images\n",
    "To prevent overfitting use image augementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#for training dataset\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True) \n",
    "\n",
    "#for test set\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "#Thumbrule : copy from keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching, & Fitting the Images to the network\n",
    "Fetches images from directory.\n",
    "The classes should be arranged in seperate sub folders. \n",
    "This is the beauty of the keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images belonging to 2 classes.\n",
      "Found 6 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "6/6 [==============================] - 3s - loss: 2.1638 - acc: 0.5556 - val_loss: 1.3750 - val_acc: 0.5000\n",
      "Epoch 2/25\n",
      "6/6 [==============================] - 0s - loss: 1.0194 - acc: 0.4720 - val_loss: 1.0217 - val_acc: 0.5000\n",
      "Epoch 3/25\n",
      "6/6 [==============================] - 0s - loss: 0.7982 - acc: 0.5840 - val_loss: 0.6976 - val_acc: 0.6667\n",
      "Epoch 4/25\n",
      "6/6 [==============================] - 0s - loss: 0.6941 - acc: 0.6401 - val_loss: 1.1379 - val_acc: 0.5000\n",
      "Epoch 5/25\n",
      "6/6 [==============================] - 0s - loss: 0.9086 - acc: 0.3361 - val_loss: 0.8111 - val_acc: 0.3333\n",
      "Epoch 6/25\n",
      "6/6 [==============================] - 0s - loss: 0.7876 - acc: 0.4720 - val_loss: 0.8311 - val_acc: 0.5000\n",
      "Epoch 7/25\n",
      "6/6 [==============================] - 0s - loss: 0.5263 - acc: 0.8081 - val_loss: 0.7157 - val_acc: 0.6667\n",
      "Epoch 8/25\n",
      "6/6 [==============================] - 0s - loss: 0.5081 - acc: 0.8889 - val_loss: 0.9020 - val_acc: 0.1667\n",
      "Epoch 9/25\n",
      "6/6 [==============================] - 0s - loss: 0.5430 - acc: 0.7521 - val_loss: 0.9095 - val_acc: 0.3333\n",
      "Epoch 10/25\n",
      "6/6 [==============================] - 0s - loss: 0.4521 - acc: 0.7521 - val_loss: 0.7314 - val_acc: 0.5000\n",
      "Epoch 11/25\n",
      "6/6 [==============================] - 0s - loss: 0.3490 - acc: 0.8081 - val_loss: 1.0840 - val_acc: 0.1667\n",
      "Epoch 12/25\n",
      "6/6 [==============================] - 2s - loss: 0.2736 - acc: 0.9440 - val_loss: 0.8512 - val_acc: 0.6667\n",
      "Epoch 13/25\n",
      "6/6 [==============================] - 3s - loss: 0.3247 - acc: 0.8319 - val_loss: 0.9308 - val_acc: 0.1667\n",
      "Epoch 14/25\n",
      "6/6 [==============================] - 2s - loss: 0.2524 - acc: 0.9440 - val_loss: 1.1157 - val_acc: 0.5000\n",
      "Epoch 15/25\n",
      "6/6 [==============================] - 2s - loss: 0.2128 - acc: 0.9444 - val_loss: 1.2729 - val_acc: 0.1667\n",
      "Epoch 16/25\n",
      "6/6 [==============================] - 2s - loss: 0.3035 - acc: 0.8319 - val_loss: 1.2928 - val_acc: 0.3333\n",
      "Epoch 17/25\n",
      "6/6 [==============================] - 2s - loss: 0.2276 - acc: 0.9440 - val_loss: 1.1673 - val_acc: 0.3333\n",
      "Epoch 18/25\n",
      "6/6 [==============================] - 2s - loss: 0.1559 - acc: 0.9440 - val_loss: 1.0455 - val_acc: 0.3333\n",
      "Epoch 19/25\n",
      "6/6 [==============================] - 2s - loss: 0.1550 - acc: 1.0000 - val_loss: 1.0403 - val_acc: 0.3333\n",
      "Epoch 20/25\n",
      "6/6 [==============================] - 1s - loss: 0.1508 - acc: 1.0000 - val_loss: 0.8035 - val_acc: 0.3333\n",
      "Epoch 21/25\n",
      "6/6 [==============================] - 1s - loss: 0.0883 - acc: 1.0000 - val_loss: 1.4143 - val_acc: 0.1667\n",
      "Epoch 22/25\n",
      "6/6 [==============================] - 1s - loss: 0.1039 - acc: 1.0000 - val_loss: 0.8198 - val_acc: 0.5000\n",
      "Epoch 23/25\n",
      "6/6 [==============================] - 1s - loss: 0.0710 - acc: 1.0000 - val_loss: 1.7492 - val_acc: 0.1667\n",
      "Epoch 24/25\n",
      "6/6 [==============================] - 1s - loss: 0.1717 - acc: 0.9440 - val_loss: 1.8721 - val_acc: 0.3333\n",
      "Epoch 25/25\n",
      "6/6 [==============================] - 2s - loss: 0.2194 - acc: 0.9440 - val_loss: 1.6505 - val_acc: 0.1667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bc8c124b70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For Training Data Set\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'training_set',\n",
    "        target_size=(64,64),\n",
    "        batch_size=3,\n",
    "        class_mode='binary')\n",
    "#For Test Data Set\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'test_set',\n",
    "        target_size=(64,64),\n",
    "        batch_size=3,\n",
    "        class_mode='binary')\n",
    "\n",
    "#steps per epoch = unique samples in training/batch_size\n",
    "#validation steps = unique samples in test/batch_size\n",
    "#epochs = no of iterations on the data\n",
    "cnn.fit_generator(\n",
    "        training_set,\n",
    "        steps_per_epoch=6,\n",
    "        epochs=25,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=2)\n",
    "#I am using less no of images as i am running on my local machine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting this Image\n",
    "Image 1:\n",
    "![title](cat_predict.png)\n",
    "Image 2:\n",
    "![title](dog_predict.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.]\n",
      "[ 0.]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image as image_utils\n",
    "import numpy as np\n",
    "def predict(path):\n",
    "    #Loading the image to be predicted\n",
    "    #Target size is same as the target size of fit_generator\n",
    "    img = image_utils.load_img(path, target_size=(64,64))\n",
    "    #You cannot load image to network. You have to convert into Array\n",
    "    img = image_utils.img_to_array(img)\n",
    "    #You have to add an extra column, because keras loads images in batches. \n",
    "    #As you are sending single image, you have to tell keras that you are sending single image\n",
    "    #you can print the img to confirm by yourself\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    #Finally, predicting the image\n",
    "    result = cnn.predict_on_batch(img)\n",
    "    #Showing the results\n",
    "    print(result[0])\n",
    "\n",
    "predict('cat_predict.png')\n",
    "predict('dog_predict.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see its predicting wrong. This is due to improper training. This is just for demo. So full length training is not done. \n",
    "The CNN architecture is absolutely correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "cnn.save('raju_model.h5')  # creates a HDF5 file 'my_model.h5'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
